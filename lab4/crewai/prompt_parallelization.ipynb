{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6d25c5",
   "metadata": {},
   "source": [
    "# Prompt Parallelization Workflow\n",
    "In this notebook, we will build a content moderation system specifically designed for media and entertainment companies using the Prompt Parallelization pattern with CrewAI framework. This pattern allows us to process media content through multiple specialized LLM prompts in parallel and then aggregate the results.\n",
    "\n",
    "At a high level, we'll be creating a media content moderation system that:\n",
    "\n",
    "1. Takes content as input (scripts, user comments, social posts, etc.)\n",
    "2. Analyzes it from multiple perspectives in parallel:\n",
    "  - Explicit language detection and age-appropriate terminology\n",
    "  - Inappropriate themes evaluation and cultural sensitivity\n",
    "  - Misleading content identification and copyright concerns\n",
    "  - Sentiment analysis and brand alignment assessment\n",
    "3. Aggregates the results into a comprehensive moderation report tailored for media platforms\n",
    "\n",
    "\n",
    "The following diagram depicts the workflow for a parallelization workflow implemented in Langgraph:\n",
    "\n",
    "<img src=\"../../imgs/strands-parallel-llm-architecture.png\" width=\"800\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd0cc8",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import the necessary CrewAI Flow components and Pydantic for data modeling. These libraries will enable us to create the parallel processing workflow and define structured data models for our content analysis agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40021501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, and_, start\n",
    "from pydantic import BaseModel\n",
    "from crewai import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452de3e",
   "metadata": {},
   "source": [
    "## Configure Logging\n",
    "\n",
    "Set up logging configuration to track the execution of our content analysis workflow. This will help us monitor the process and debug any issues that might arise during the parallel analysis execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79193b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a60e9",
   "metadata": {},
   "source": [
    "## Define Agent State Model\n",
    "\n",
    "Create a Pydantic data model to represent the state that will be shared across all analysis agents. This includes the input content and fields to store the results from each specialized analysis agent (explicit language, inappropriate themes, misleading content, and sentiment analysis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd23155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(BaseModel):\n",
    "    content: str = None\n",
    "    explicitLanguageAnalysis: str = \"\"\n",
    "    inappropriateThemeAnalysis: str = \"\"\n",
    "    misleadingContentAnalysis: str= \"\"\n",
    "    sentimentAnalysis: str = \"\"\n",
    "    final_result: str = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9966e98",
   "metadata": {},
   "source": [
    "## Content Analysis Parallel Flow Implementation\n",
    "\n",
    "This is the core implementation of our parallel content analysis workflow using CrewAI Flow. The class defines four specialized analysis agents that run in parallel:\n",
    "\n",
    "1. **Explicit Language Analysis Agent** - Analyzes content for profanity, age-appropriate language, and provides age rating recommendations\n",
    "2. **Inappropriate Theme Analysis Agent** - Identifies problematic themes, cultural sensitivity issues, and regional content concerns  \n",
    "3. **Misleading Content Analysis Agent** - Detects factual inaccuracies, potential copyright issues, and content requiring legal review\n",
    "4. **Sentiment Analysis Agent** - Evaluates emotional tone, brand alignment, and potential audience impact\n",
    "\n",
    "After all four agents complete their analysis, an **Aggregator** combines all results into a comprehensive moderation report with platform-specific recommendations for streaming services, broadcast TV, social media, and international distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentAnalysisParallelFlow(Flow[AgentState]):\n",
    "\n",
    "    @start()\n",
    "    def start_method(self):\n",
    "        pass\n",
    "\n",
    "    @listen(start_method)\n",
    "    def explicitLanguageAnalysisAgent(self):\n",
    "        system_prompt = \"\"\"You are a content moderator for a major media and entertainment company specializing in identifying explicit language and age-appropriate content.\n",
    "\n",
    "# Analyze the following content for:\n",
    "\n",
    "1. Explicit language and profanity\n",
    "2. Age-appropriate terminology\n",
    "3. Content suitable for different audience age ratings (G, PG, PG-13, R, etc.)\n",
    "4. Dialogue or descriptions that may require parental guidance\n",
    "\n",
    "## Provide a detailed report with:\n",
    "\n",
    "1. Overall assessment (Family-Friendly/Teen-Appropriate/Mature/Adult-Only)\n",
    "2. Specific instances of explicit language or age-inappropriate content found (if any)\n",
    "3. Age rating recommendation (G, PG, PG-13, R, NC-17, etc.)\n",
    "4. Recommendations for content revision to meet specific audience age targets\n",
    "\n",
    "Format your response as JSON:\n",
    "\n",
    "   {\n",
    "      \"assessment\": \"Family-Friendly/Teen-Appropriate/Mature/Adult-Only\",\n",
    "      \"instances\": [\"example1\", \"example2\"],\n",
    "      \"age_rating\": \"PG-13\",\n",
    "      \"revision_recommendations\": \"Your recommendations here\"\n",
    "   }\n",
    "\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": self.state.content}\n",
    "        ]\n",
    "        llm = LLM(model=\"bedrock/us.amazon.nova-micro-v1:0\")\n",
    "        \n",
    "        response = llm.call(messages=messages)\n",
    "        self.state.explicitLanguageAnalysis = response\n",
    "        \n",
    "    @listen(start_method)\n",
    "    def inappropriateThemeAnalysisAgent(self):\n",
    "        system_prompt = \"\"\"You are a content moderator for a major media and entertainment company specializing in identifying inappropriate themes and cultural sensitivity issues.\n",
    "\n",
    "# Analyze the following content for:\n",
    "\n",
    "1. Inappropriate themes such as violence, discrimination, or harmful ideologies\n",
    "2. Cultural sensitivity concerns across global audiences\n",
    "3. Potentially offensive stereotypes or representations\n",
    "4. Content that may be inappropriate for certain regions or markets\n",
    "\n",
    "\n",
    "## Provide a detailed report with:\n",
    "\n",
    "1. Overall assessment (Universally Acceptable/Regionally Sensitive/Potentially Offensive)\n",
    "2. Specific inappropriate themes or cultural sensitivity issues identified (if any)\n",
    "3. Regions or demographics that may find the content problematic\n",
    "4. Recommendations for content revision to improve cultural sensitivity\n",
    "\n",
    "# Format your response as JSON:\n",
    "\n",
    "   {\n",
    "      \"assessment\": \"Universally Acceptable/Regionally Sensitive/Potentially Offensive\",\n",
    "      \"themes\": [\"theme1\", \"theme2\"],\n",
    "      \"sensitive_regions\": [\"region1\", \"region2\"],\n",
    "      \"revision_recommendations\": \"Your recommendations here\"\n",
    "   }\n",
    "\"\"\"\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.state.content}\n",
    "            ]\n",
    "        llm = LLM(model=\"bedrock/us.amazon.nova-micro-v1:0\")\n",
    "        response = llm.call(messages=messages)\n",
    "        self.state.inappropriateThemeAnalysis = response\n",
    "\n",
    "    @listen(start_method)\n",
    "    def misleadingContentAnalysisAgent(self):\n",
    "        system_prompt = \"\"\"You are a content moderator for a major media and entertainment company specializing in identifying misleading content, factual inaccuracies, and potential copyright issues.\n",
    "\n",
    "# Analyze the following content for:\n",
    "\n",
    "1. Misleading claims or factual inaccuracies\n",
    "2. Potential copyright or intellectual property concerns\n",
    "3. Unauthorized references to protected brands, characters, or properties\n",
    "4. Content that may require fact-checking or legal review\n",
    "\n",
    "## Provide a detailed report with:\n",
    "\n",
    "1. Overall assessment (Factually Sound/Needs Verification/Potentially Infringing)\n",
    "2. Specific misleading claims or factual inaccuracies identified (if any)\n",
    "3. Potential copyright or IP concerns\n",
    "4. Recommendations for content revision to address factual or legal issues\n",
    "\n",
    "Format your response as JSON:\n",
    "\n",
    "   {\n",
    "      \"assessment\": \"Factually Sound/Needs Verification/Potentially Infringing\",\n",
    "      \"inaccuracies\": [\"inaccuracy1\", \"inaccuracy2\"],\n",
    "      \"copyright_concerns\": [\"concern1\", \"concern2\"],\n",
    "      \"revision_recommendations\": \"Your recommendations here\"\n",
    "   }\n",
    "\"\"\" \n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.state.content}\n",
    "            ]\n",
    "        llm = LLM(model=\"bedrock/us.amazon.nova-lite-v1:0\")\n",
    "        response = llm.call(messages=messages)\n",
    "        self.state.misleadingContentAnalysis = response\n",
    "\n",
    "    @listen(start_method)\n",
    "    def sentimentAnalysisAgent(self):\n",
    "        system_prompt = \"\"\"You are a content moderator for a major media and entertainment company specializing in sentiment analysis and brand alignment.\n",
    "\n",
    "# Analyze the following content for:\n",
    "\n",
    "1. Overall emotional tone and sentiment\n",
    "2. Alignment with typical media brand values (positivity, inclusivity, creativity, etc.)\n",
    "3. Potential impact on audience perception and brand reputation\n",
    "4. Emotional resonance with target demographics\n",
    "\n",
    "# Provide a detailed report with:\n",
    "1. Overall sentiment (Positive/Neutral/Negative)\n",
    "2. Brand alignment assessment (Aligned/Partially Aligned/Misaligned)\n",
    "3. Potential emotional impact on viewers/readers\n",
    "4. Recommendations for content revision to improve brand alignment\n",
    "\n",
    "Format your response as JSON:\n",
    "\n",
    "{\n",
    "    \"sentiment\": \"Positive/Neutral/Negative\",\n",
    "    \"brand_alignment\": \"Aligned/Partially Aligned/Misaligned\",\n",
    "    \"emotional_impact\": \"Your assessment here\",\n",
    "    \"revision_recommendations\": \"Your recommendations here\"\n",
    "}\n",
    "\"\"\"\n",
    "        messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": self.state.content}\n",
    "                ]\n",
    "        llm = LLM(model=\"bedrock/us.amazon.nova-lite-v1:0\")\n",
    "        response = llm.call(messages=messages)\n",
    "        self.state.sentimentAnalysis = response\n",
    "\n",
    "    @listen(and_(explicitLanguageAnalysisAgent, inappropriateThemeAnalysisAgent, misleadingContentAnalysisAgent, sentimentAnalysisAgent))\n",
    "    def aggregator(self):\n",
    "        system_prompt = \"\"\"You are a senior content moderator for a major media and entertainment company responsible for creating comprehensive moderation reports with platform-specific recommendations.\n",
    "\n",
    "   You are given the moderation analysis reports as described below:\n",
    "   \n",
    "   - Explicit Language & Age-Appropriate Analysis\n",
    "   - Inappropriate Themes & Cultural Sensitivity Analysis\n",
    "   - Misleading Content & Copyright Analysis\n",
    "   - Sentiment & Brand Alignment Analysis\n",
    "\n",
    "\n",
    "   Based on these reports, provide:\n",
    "   1. Overall moderation decision (Approve/Revise/Reject)\n",
    "   2. Summary of key concerns from all analyses\n",
    "   3. Platform-specific recommendations for:\n",
    "      - Streaming platforms (Netflix, Disney+, Prime Video, etc.)\n",
    "      - Broadcast television\n",
    "      - Social media platforms\n",
    "      - International distribution\n",
    "   4. Specific content tags or warnings recommended\n",
    "   5. Justification for your decision\n",
    "\n",
    "   Format your response as a well-structured report with clear sections for each platform type.\n",
    "\"\"\"\n",
    "        explicitLanguageAnalysis = self.state.explicitLanguageAnalysis\n",
    "        inappropriateThemeAnalysis = self.state.inappropriateThemeAnalysis\n",
    "        misleadingContentAnalysis = self.state.misleadingContentAnalysis\n",
    "        sentimentAnalysis = self.state.sentimentAnalysis\n",
    "\n",
    "        mediaPlatformRecommendations_prompt = f\"\"\"## Explicit Language & Age-Appropriate Analysis Report:\n",
    "\n",
    "{explicitLanguageAnalysis}\n",
    "\n",
    "## Inappropriate Themes & Cultural Sensitivity Analysis Report:\n",
    "\n",
    "{inappropriateThemeAnalysis}\n",
    "\n",
    "## Misleading Content & Copyright Analysis Report:\n",
    "\n",
    "{misleadingContentAnalysis}\n",
    "\n",
    "\n",
    "## Sentiment & Brand Alignment Analysis Report:\n",
    "\n",
    "{sentimentAnalysis}\n",
    "\n",
    "\"\"\"\n",
    "        messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": mediaPlatformRecommendations_prompt}\n",
    "                ]\n",
    "        llm = LLM(model=\"bedrock/us.amazon.nova-pro-v1:0\")\n",
    "        response = llm.call(messages=messages)\n",
    "        return { \"final_result\" : response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7b0c6",
   "metadata": {},
   "source": [
    "## Sample Script Content for Analysis\n",
    "\n",
    "Define a sample TV/movie script that contains various elements requiring content moderation analysis. This crime drama script excerpt includes explicit language, violent themes, and mature content that will trigger responses from all four analysis agents, demonstrating the comprehensive moderation capabilities of our parallel workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"FADE IN:\n",
    "\n",
    "   EXT. CITY STREET - NIGHT\n",
    "\n",
    "   Rain pours down as DETECTIVE MORGAN (45, hardened) stands over a body covered by a sheet. Lightning flashes, illuminating the grim scene.\n",
    "\n",
    "   DETECTIVE MORGAN\n",
    "   (lighting a cigarette)\n",
    "   Third one this month. Same damn signature.\n",
    "\n",
    "   OFFICER JENKINS (30s) approaches, looking queasy.\n",
    "\n",
    "   OFFICER JENKINS\n",
    "   The mayor's going to have a fit. The press is already calling this guy \"The Midnight Butcher.\"\n",
    "\n",
    "   DETECTIVE MORGAN\n",
    "   I don't give a damn what they call him. I'm going to catch this son of a bitch before he cuts up another girl.\n",
    "\n",
    "   Morgan kneels down and pulls back the sheet, revealing a young woman's face, pale and lifeless.\n",
    "\n",
    "   DETECTIVE MORGAN\n",
    "   (whispering)\n",
    "   I promise you justice, sweetheart. Whatever it takes.\n",
    "\n",
    "   He stands, tosses his cigarette into a puddle.\n",
    "\n",
    "   DETECTIVE MORGAN\n",
    "   Jenkins, get me everything on the victim. And I mean everything. Where she worked, who she dated, what goddamn toothpaste she used.\n",
    "\n",
    "   OFFICER JENKINS\n",
    "   But sir, it's almost midnight andâ€”\n",
    "\n",
    "   DETECTIVE MORGAN\n",
    "   (interrupting)\n",
    "   Evil doesn't sleep, why should we?\n",
    "\n",
    "   Morgan walks away as lightning flashes again, his silhouette momentarily frozen against the night sky.\n",
    "\n",
    "   FADE OUT.\n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394384b",
   "metadata": {},
   "source": [
    "## Execute Content Analysis Flow\n",
    "\n",
    "Run the parallel content analysis workflow asynchronously on our sample script. This will trigger all four analysis agents to process the content simultaneously, each focusing on their specialized area of expertise, before aggregating the results into a comprehensive moderation report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await ContentAnalysisParallelFlow().kickoff_async(inputs = {\n",
    "    \"content\" : script})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8da583",
   "metadata": {},
   "source": [
    "## Display Analysis Results\n",
    "\n",
    "Print the comprehensive content moderation report generated by our parallel analysis workflow. The output includes the overall moderation decision, key concerns from each analysis agent, and platform-specific recommendations for different distribution channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8f3ea",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we successfully implemented a **Prompt Parallelization** workflow using CrewAI for content moderation in the media and entertainment industry. Here's what we built and demonstrated:\n",
    "\n",
    "### **Specialized Analysis Agents**\n",
    "1. **Explicit Language Analysis Agent** - Detected profanity, assessed age-appropriateness, and provided content ratings (G, PG, PG-13, R, etc.)\n",
    "2. **Inappropriate Theme Analysis Agent** - Identified problematic themes, cultural sensitivity issues, and regional content concerns\n",
    "3. **Misleading Content Analysis Agent** - Analyzed factual accuracy, copyright concerns, and legal compliance requirements\n",
    "4. **Sentiment Analysis Agent** - Evaluated emotional tone, brand alignment, and potential audience impact\n",
    "\n",
    "This implementation showcases how modern AI workflows can streamline content moderation processes while ensuring comprehensive analysis and compliance across multiple distribution platforms and global markets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
